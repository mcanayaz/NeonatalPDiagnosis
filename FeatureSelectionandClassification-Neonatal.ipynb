{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import gc\n",
    "#import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from PIL import Image\n",
    "from albumentations import *\n",
    "from skimage.transform import resize\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_fscore_support, accuracy_score\n",
    "\n",
    "\n",
    "# Load libraries\n",
    "from pandas import read_csv\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Normal SVM\n",
    "\n",
    "#import all necessary libraries\n",
    "import sklearn\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "import matplotlib.pyplot as plt  # doctest: +SKIP\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import os\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import isnan\n",
    "from numpy import asarray\n",
    "from numpy import polyfit\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib import pyplot\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f=np.load(\"binaryaccts03/effb0baccts03_f.npy\")\n",
    "y_train1=np.load(\"binaryaccts03/effb0baccts03_y.npy\")\n",
    "\n",
    "\"\"\"f_1=np.load(\"featuresaysehoca/effb0_f.npy\")\n",
    "y_train1_1=np.load(\"featuresaysehoca/effb0_y.npy\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1=np.load(\"binaryaccts03/effb0baccts03_f.npy\")\n",
    "y_train1_1=np.load(\"binaryaccts03/effb0baccts03_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_2=np.load(\"binaryaccts03/effb1baccts03_f.npy\")\n",
    "y_train1_2=np.load(\"binaryaccts03/effb1baccts03_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_3=np.load(\"binaryaccts03/effb2baccts03_f.npy\")\n",
    "y_train1_3=np.load(\"binaryaccts03/effb2baccts03_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1.shape ,y_train1_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1==f_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate a logistic regression model using k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(f_1, y_train1_1, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label = X_train,Y_train\n",
    "val_feature, val_label = X_validation,Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_feature)\n",
    "train_fea1 = pca.transform(train_feature)[:, :100]\n",
    "val_fea1= pca.transform(val_feature)[:, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff0train=train_fea1 \n",
    "eff0trainlabel=train_label\n",
    "eff0val=val_fea1\n",
    "eff0val_label=val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(f_2, y_train1_2, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label = X_train,Y_train\n",
    "val_feature, val_label = X_validation,Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_feature)\n",
    "train_fea1 = pca.transform(train_feature)[:, :100]\n",
    "val_fea1= pca.transform(val_feature)[:, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff1train=train_fea1 \n",
    "eff1trainlabel=train_label\n",
    "eff1val=val_fea1\n",
    "eff1val_label=val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_validation, Y_train, Y_validation = train_test_split(f_3, y_train1_3, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature, train_label = X_train,Y_train\n",
    "val_feature, val_label = X_validation,Y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(train_feature)\n",
    "train_fea1 = pca.transform(train_feature)[:, :100]\n",
    "val_fea1= pca.transform(val_feature)[:, :100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff2train=train_fea1 \n",
    "eff2trainlabel=train_label\n",
    "eff2val=val_fea1\n",
    "eff2val_label=val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eff2train==eff1train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = np.concatenate((eff0train,eff1train),axis=1)\n",
    "print(con1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con2=np.concatenate((con1,eff2train),axis=1)\n",
    "print(con2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_val=np.concatenate((eff0val,eff1val),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_val1=np.concatenate((con_val,eff2val),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea=con2\n",
    "val_fea=con_val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea=train_fea1\n",
    "val_fea=val_fea1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fea.shape,val_fea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normal SVM\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "#load the dataset and split it into training and testing sets\n",
    "\n",
    "# train the model on train set without using GridSearchCV \n",
    "\n",
    "#cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "# create model\n",
    "#model = SVC() \n",
    "#model=RidgeClassifier()\n",
    "#model=KNeighborsClassifier()\n",
    "model=XGBClassifier()\n",
    "model.fit(train_fea, train_label) \n",
    "# evaluate model\n",
    "\n",
    "   \n",
    "# print prediction results \n",
    "predictions = model.predict(val_fea) \n",
    "print(classification_report(val_label, predictions)) \n",
    "class_names = [\"normal\",\"a-normal\"]\n",
    "\n",
    "plot_confusion_matrix(model, val_fea,val_label,display_labels=class_names,\n",
    "                                 cmap=plt.cm.Purples)  # doctest: +SKIP\n",
    "\n",
    "#plt.savefig(\"KNNeff0pca.png\",dpi=300)\n",
    "\n",
    "plt.show()  # doctest: +SKIP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "predictions = cross_val_predict(model, train_fea, train_label, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p,r,f,g=prf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, cohen_kappa_score,balanced_accuracy_score,precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "Acc=accuracy_score(val_label, model.predict(val_fea))\n",
    "prf=precision_recall_fscore_support(val_label, model.predict(val_fea), average='weighted')\n",
    "Kappa=cohen_kappa_score(val_label, model.predict(val_fea))\n",
    "#rf_auc = balanced_accuracy_score(val_label, model.predict(val_fea))\n",
    "MSE=metrics.mean_squared_error(val_label, model.predict(val_fea))\n",
    "RMSE=np.sqrt(metrics.mean_squared_error(val_label, model.predict(val_fea)))\n",
    "MAE=metrics.mean_absolute_error(val_label, model.predict(val_fea))\n",
    "p,r,f,g=prf\n",
    "data=[Acc,p,r,f,MSE,RMSE,MAE,Kappa]\n",
    "abd=pd.DataFrame(data,columns=['Sonuclar'])\n",
    "print(\"Acc: \"+ str(Acc),\"Precision: \"+str(p),\"Recall: \"+str(r),\"F-score: \"+str(f), \"MSE: \"+str(MSE),\"RMSE: \"+str(RMSE), \"MAE: \"+str(MAE),\"Kappa: \"+str(Kappa))\n",
    "abd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create the dataset\n",
    "def get_dataset():\n",
    "\tX, y = train_fea,train_label\n",
    "\treturn X, y\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = list()\n",
    "    #models.append(LogisticRegression())\n",
    "    models.append(RidgeClassifier())\n",
    "    models.append(SGDClassifier())\n",
    "    models.append(PassiveAggressiveClassifier())\n",
    "    models.append(KNeighborsClassifier())\n",
    "    models.append(DecisionTreeClassifier())\n",
    "    models.append(ExtraTreeClassifier())\n",
    "    models.append(LinearSVC())\n",
    "    models.append(SVC())    \n",
    "    models.append(GaussianNB())\n",
    "    models.append(RandomForestClassifier())\n",
    "    \n",
    "\n",
    "    return models\n",
    "\n",
    "# evaluate the model using a given test condition\n",
    "def evaluate_model(cv, model):\n",
    "    # get the dataset\n",
    "    X, y = get_dataset()\n",
    "    \n",
    "    # evaluate the model\n",
    "    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores)\n",
    "\n",
    "# define test conditions\n",
    "ideal_cv = LeaveOneOut()\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "# get the list of models to consider\n",
    "models = get_models()\n",
    "# collect results\n",
    "ideal_results, cv_results = list(), list()\n",
    "data1,data2=[],[]\n",
    "# evaluate each model\n",
    "for model in models:\n",
    "    # evaluate model using each test condition\n",
    "    cv_mean = evaluate_model(cv, model)\n",
    "    ideal_mean = evaluate_model(ideal_cv, model)\n",
    "    # check for invalid results\n",
    "    if isnan(cv_mean) or isnan(ideal_mean):\n",
    "        continue\n",
    "# store results\n",
    "    cv_results.append(cv_mean)\n",
    "    ideal_results.append(ideal_mean)\n",
    "# summarize progress\n",
    "    print('>%s: ideal=%.3f, cv=%.3f' % (type(model).__name__, ideal_mean, cv_mean))\n",
    "    data1.append(ideal_mean)\n",
    "    data2.append(cv_mean)\n",
    "ideal_sonuc=pd.DataFrame(data1,columns=[\"Ideal\"])\n",
    "\n",
    "cv_sonuc=pd.DataFrame(data2,columns=[\"CV\"])\n",
    "\n",
    "# calculate the correlation between each test condition\n",
    "corr, _ = pearsonr(cv_results, ideal_results)\n",
    "print('Correlation: %.3f' % corr)\n",
    "# scatter plot of results\n",
    "pyplot.scatter(cv_results, ideal_results)\n",
    "# plot the line of best fit\n",
    "coeff, bias = polyfit(cv_results, ideal_results, 1)\n",
    "line = coeff * asarray(cv_results) + bias\n",
    "pyplot.plot(cv_results, line, color='r')\n",
    "# label the plot\n",
    "pyplot.title('10-fold CV vs LOOCV Mean Accuracy')\n",
    "pyplot.xlabel('Mean Accuracy (10-fold CV)')\n",
    "pyplot.ylabel('Mean Accuracy (LOOCV)')\n",
    "# show the plot\n",
    "pyplot.savefig(\"sonuceff0.png\",dpi=300)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[cv_sonuc,ideal_sonuc]\n",
    "result = pd.concat(frames, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
